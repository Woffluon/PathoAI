{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY_4doozDgKh"
      },
      "source": [
        "# CIA-Net: Contour-aware Information Aggregation Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4h7EzJ4-DgKl"
      },
      "source": [
        "## 1. Environment Setup & Configuration\n",
        "Initializes the runtime environment, installs dependencies (Albumentations), and defines global hyperparameters ensuring reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdAI9BRnDgKm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, backend as K\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import xml.etree.ElementTree as ET\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from scipy import ndimage as ndi\n",
        "from skimage.morphology import remove_small_objects\n",
        "from skimage.measure import label\n",
        "\n",
        "# --- 3rd Party Libraries ---\n",
        "os.system('pip install -q albumentations')\n",
        "import albumentations as A\n",
        "\n",
        "# --- Configuration ---\n",
        "warnings.filterwarnings('ignore')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "tf.keras.mixed_precision.set_global_policy('float32')\n",
        "\n",
        "# --- Hyperparameters ---\n",
        "SEED = 42\n",
        "PATCH_SIZE = (224, 224)\n",
        "IMG_SIZE = PATCH_SIZE\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 100\n",
        "LAMBDA_CONTOUR = 0.42  # Paper Eq. 4\n",
        "GAMMA_STL = 0.2\n",
        "\n",
        "# --- Phase Configs ---\n",
        "WARMUP_EPOCHS = 20\n",
        "RESCUE_EPOCHS = 30\n",
        "SOTA_EPOCHS = 100\n",
        "\n",
        "# --- Paths ---\n",
        "DRIVE_MOUNT_PATH = \"/content/drive\"\n",
        "DRIVE_DATA_PATH = \"/content/drive/MyDrive/\"\n",
        "MONUSEG_TRAIN_ZIP = \"MoNuSeg_Training_Data.zip\"\n",
        "MONUSEG_TEST_ZIP = \"MoNuSeg_Test_Data.zip\"\n",
        "TRAIN_EXTRACT_DIR = \"/content/MoNuSeg_Train\"\n",
        "TEST_EXTRACT_DIR = \"/content/MoNuSeg_Test\"\n",
        "\n",
        "# --- Reproducibility ---\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "set_seed(SEED)\n",
        "\n",
        "# --- UI Utilities ---\n",
        "class Colors:\n",
        "    HEADER = '\\033[95m'\n",
        "    INFO = '\\033[94m'\n",
        "    SUCCESS = '\\033[92m'\n",
        "    WARNING = '\\033[93m'\n",
        "    ERROR = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "\n",
        "print(f\"{Colors.SUCCESS}[OK] Environment Initialized. IMG_SIZE: {IMG_SIZE}{Colors.ENDC}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8YqMVhbDgKo"
      },
      "source": [
        "## 2. Data Acquisition & Ingestion\n",
        "Mounts Google Drive and safely extracts the MoNuSeg dataset zips into the local runtime storage for high-speed I/O."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOxN19WbDgKo"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "\n",
        "if not os.path.exists(DRIVE_MOUNT_PATH):\n",
        "    drive.mount(DRIVE_MOUNT_PATH)\n",
        "\n",
        "def unzip_data(zip_path, extract_to):\n",
        "    full_zip_path = os.path.join(DRIVE_DATA_PATH, zip_path)\n",
        "    if not os.path.exists(full_zip_path):\n",
        "        print(f\"{Colors.ERROR}[ERROR] File not found: {full_zip_path}{Colors.ENDC}\")\n",
        "        return False\n",
        "    if not os.path.exists(extract_to):\n",
        "        os.makedirs(extract_to)\n",
        "        with zipfile.ZipFile(full_zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_to)\n",
        "    return True\n",
        "\n",
        "status_train = unzip_data(MONUSEG_TRAIN_ZIP, TRAIN_EXTRACT_DIR)\n",
        "status_test = unzip_data(MONUSEG_TEST_ZIP, TEST_EXTRACT_DIR)\n",
        "\n",
        "if not (status_train and status_test):\n",
        "    raise FileNotFoundError(\"Required Dataset Zip files not found in Drive.\")\n",
        "print(f\"{Colors.SUCCESS}[OK] Data Extracted Successfully.{Colors.ENDC}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OFi-WRuDgKp"
      },
      "source": [
        "## 3. Data Processing Pipeline\n",
        "Handles high-resolution image loading, XML annotation parsing, staining normalization (optional), and builds the TensorFlow Data Pipeline with advanced augmentations (Albumentations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4YtCBs3DgKq"
      },
      "outputs": [],
      "source": [
        "# --- 3.1 Preprocessing Utilities ---\n",
        "\n",
        "def normalize_staining(img, Io=240, alpha=1, beta=0.15):\n",
        "    try:\n",
        "        HER = np.array([[0.650, 0.704, 0.286], [0.072, 0.990, 0.105], [0.268, 0.570, 0.776]])\n",
        "        h, w, c = img.shape\n",
        "        img = img.reshape((-1, 3))\n",
        "        OD = -np.log((img.astype(float) + 1) / Io)\n",
        "        ODhat = OD[np.all(OD > beta, axis=1)]\n",
        "        if len(ODhat) < 10: return img.reshape((h, w, c))\n",
        "        eigvals, eigvecs = np.linalg.eigh(np.cov(ODhat.T))\n",
        "        That = ODhat.dot(eigvecs[:, 1:3])\n",
        "        phi = np.arctan2(That[:, 1], That[:, 0])\n",
        "        minPhi, maxPhi = np.percentile(phi, alpha), np.percentile(phi, 100 - alpha)\n",
        "        vMin = eigvecs[:, 1:3].dot(np.array([(np.cos(minPhi), np.sin(minPhi))]).T)\n",
        "        vMax = eigvecs[:, 1:3].dot(np.array([(np.cos(maxPhi), np.sin(maxPhi))]).T)\n",
        "        HE = np.array((vMin[:, 0], vMax[:, 0])).T if vMin[0] > vMax[0] else np.array((vMax[:, 0], vMin[:, 0])).T\n",
        "        Y = np.reshape(OD, (-1, 3)).T\n",
        "        C = np.linalg.lstsq(HE, Y, rcond=None)[0]\n",
        "        maxC = np.array([1.9705, 1.0308])\n",
        "        C = np.array([C[0] / maxC[0], C[1] / maxC[1]])\n",
        "        Inorm = Io * np.exp(-np.dot(HER[:, 0:2], C * maxC[:, np.newaxis]))\n",
        "        return np.clip(np.reshape(Inorm.T, (h, w, c)), 0, 255).astype(np.uint8)\n",
        "    except: return img.reshape((h, w, c))\n",
        "\n",
        "def process_xml_annotations(xml_path, image_shape):\n",
        "    tree = ET.parse(xml_path); root = tree.getroot()\n",
        "    nuclei_mask = np.zeros(image_shape[:2], dtype=np.uint8)\n",
        "    for region in root.findall(\".//Region\"):\n",
        "        points = [[float(v.get('X')), float(v.get('Y'))] for v in region.findall(\".//Vertex\")]\n",
        "        if len(points) > 0:\n",
        "            pts = np.array(points, np.int32).reshape((-1, 1, 2))\n",
        "            cv2.fillPoly(nuclei_mask, [pts], 255)\n",
        "\n",
        "    kernel = np.ones((3,3), np.uint8)\n",
        "    dilated = cv2.dilate(nuclei_mask, kernel, iterations=1)\n",
        "    eroded = cv2.erode(nuclei_mask, kernel, iterations=1)\n",
        "    contour_mask = (dilated - eroded > 0).astype(np.uint8) * 255\n",
        "    return nuclei_mask, contour_mask\n",
        "\n",
        "def load_data_high_res(data_dir):\n",
        "    image_paths = sorted(glob(os.path.join(data_dir, \"**\", \"*.tif\"), recursive=True))\n",
        "    images, nuclei, contours = [], [], []\n",
        "    print(f\"{Colors.INFO}Loading High-Res Data from: {data_dir}{Colors.ENDC}\")\n",
        "\n",
        "    for p in tqdm(image_paths):\n",
        "        base = os.path.splitext(os.path.basename(p))[0]\n",
        "        xml = list(glob(os.path.join(data_dir, \"**\", f\"{base}.xml\"), recursive=True))\n",
        "        if not xml: continue\n",
        "\n",
        "        img = cv2.cvtColor(cv2.imread(p), cv2.COLOR_BGR2RGB)\n",
        "        # img = normalize_staining(img) # Optional: Macenko norm\n",
        "\n",
        "        n_mask, c_mask = process_xml_annotations(xml[0], img.shape)\n",
        "\n",
        "        images.append(img)\n",
        "        nuclei.append(n_mask)\n",
        "        contours.append(c_mask)\n",
        "\n",
        "    return images, nuclei, contours\n",
        "\n",
        "# --- 3.2 Loading Raw Data ---\n",
        "X_train_raw, y_nuc_train_raw, y_con_train_raw = load_data_high_res(TRAIN_EXTRACT_DIR)\n",
        "X_test_raw, y_nuc_test_raw, y_con_test_raw = load_data_high_res(TEST_EXTRACT_DIR)\n",
        "\n",
        "# --- 3.3 Augmentation Pipeline ---\n",
        "train_transform = A.Compose([\n",
        "    A.RandomCrop(width=PATCH_SIZE[1], height=PATCH_SIZE[0]),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.RandomRotate90(p=0.5),\n",
        "    A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.5),\n",
        "    A.GridDistortion(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "], additional_targets={'nuclei': 'mask', 'contour': 'mask'})\n",
        "\n",
        "test_transform = A.Compose([\n",
        "    A.CenterCrop(width=PATCH_SIZE[1], height=PATCH_SIZE[0])\n",
        "], additional_targets={'nuclei': 'mask', 'contour': 'mask'})\n",
        "\n",
        "def process_data_train_flat(img, nuc, con):\n",
        "    data = {\"image\": img, \"nuclei\": nuc, \"contour\": con}\n",
        "    aug = train_transform(**data)\n",
        "\n",
        "    img = aug[\"image\"].astype(np.float32) / 255.0\n",
        "    nuc = (aug[\"nuclei\"] > 127).astype(np.float32)[..., np.newaxis]\n",
        "    con = (aug[\"contour\"] > 127).astype(np.float32)[..., np.newaxis]\n",
        "    return img, nuc, con\n",
        "\n",
        "def process_data_test_flat(img, nuc, con):\n",
        "    data = {\"image\": img, \"nuclei\": nuc, \"contour\": con}\n",
        "    aug = test_transform(**data)\n",
        "\n",
        "    img = aug[\"image\"].astype(np.float32) / 255.0\n",
        "    nuc = (aug[\"nuclei\"] > 127).astype(np.float32)[..., np.newaxis]\n",
        "    con = (aug[\"contour\"] > 127).astype(np.float32)[..., np.newaxis]\n",
        "    return img, nuc, con\n",
        "\n",
        "def tf_process_wrapper(img, nuc, con, is_train=True):\n",
        "    [img_out, nuc_out, con_out] = tf.numpy_function(\n",
        "        func=process_data_train_flat if is_train else process_data_test_flat,\n",
        "        inp=[img, nuc, con],\n",
        "        Tout=[tf.float32, tf.float32, tf.float32]\n",
        "    )\n",
        "    img_out.set_shape([224, 224, 3])\n",
        "    nuc_out.set_shape([224, 224, 1])\n",
        "    con_out.set_shape([224, 224, 1])\n",
        "    return img_out, {'nuclei_output': nuc_out, 'contour_output': con_out}\n",
        "\n",
        "# --- 3.4 Dataset Generator ---\n",
        "def get_generator(images, nucs, cons, is_train=True):\n",
        "    def gen():\n",
        "        for i in range(len(images)):\n",
        "            repeats = 10 if is_train else 1\n",
        "            for _ in range(repeats):\n",
        "                yield images[i], nucs[i], cons[i]\n",
        "    return gen\n",
        "\n",
        "output_signature = (\n",
        "    tf.TensorSpec(shape=(None, None, 3), dtype=tf.uint8),\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.uint8),\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.uint8)\n",
        ")\n",
        "\n",
        "train_ds = tf.data.Dataset.from_generator(\n",
        "    get_generator(X_train_raw, y_nuc_train_raw, y_con_train_raw, True),\n",
        "    output_signature=output_signature\n",
        ").map(\n",
        "    lambda i, n, c: tf_process_wrapper(i, n, c, is_train=True),\n",
        "    num_parallel_calls=tf.data.AUTOTUNE\n",
        ").batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_generator(\n",
        "    get_generator(X_test_raw, y_nuc_test_raw, y_con_test_raw, False),\n",
        "    output_signature=output_signature\n",
        ").map(\n",
        "    lambda i, n, c: tf_process_wrapper(i, n, c, is_train=False),\n",
        "    num_parallel_calls=tf.data.AUTOTUNE\n",
        ").batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# --- Validation Check ---\n",
        "print(f\"\\n{Colors.WARNING}Pipeline Integrity Check (Masks must be 0-1):{Colors.ENDC}\")\n",
        "for img, target in train_ds.take(1):\n",
        "    nuc = target['nuclei_output'][0].numpy()\n",
        "    print(f\"Nuclei Max: {nuc.max()}, Min: {nuc.min()}\")\n",
        "    if nuc.max() > 1.0:\n",
        "        print(f\"{Colors.ERROR}CRITICAL: Mask values > 1.0!{Colors.ENDC}\")\n",
        "    else:\n",
        "        print(f\"{Colors.SUCCESS}Data Format Correct.{Colors.ENDC}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g45zcsR6DgKs"
      },
      "source": [
        "## 4. CIA-Net Architecture\n",
        "Constructs the functional Keras model. Key components include:\n",
        "1.  **Encoder:** DenseNet121 (pre-trained).\n",
        "2.  **IAM (Information Aggregation Module):** Facilitates flow between Nucleus and Contour tasks.\n",
        "3.  **Decoder:** Multi-scale feature fusion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMs1KZTDDgKt"
      },
      "outputs": [],
      "source": [
        "def IAM_Module(nuc_feat, con_feat, filters, name=\"IAM\"):\n",
        "    concat = layers.Concatenate(name=f\"{name}_concat\")([nuc_feat, con_feat])\n",
        "    smooth = layers.Conv2D(filters, 3, padding='same', activation=None, name=f\"{name}_smooth\")(concat)\n",
        "    nuc_refine = layers.Conv2D(filters, 3, padding='same', activation='relu', name=f\"{name}_nuc_refine\")(smooth)\n",
        "    con_refine = layers.Conv2D(filters, 3, padding='same', activation='relu', name=f\"{name}_con_refine\")(smooth)\n",
        "    return nuc_refine, con_refine\n",
        "\n",
        "def build_cia_net(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    base_model = tf.keras.applications.DenseNet121(include_top=False, weights='imagenet', input_tensor=inputs)\n",
        "\n",
        "    # Encoder Features\n",
        "    enc_block1 = base_model.get_layer('conv1_relu').output               # 112x112\n",
        "    enc_block2 = base_model.get_layer('conv2_block6_concat').output      # 56x56\n",
        "    enc_block3 = base_model.get_layer('conv3_block12_concat').output     # 28x28\n",
        "    enc_block4 = base_model.get_layer('conv4_block24_concat').output     # 14x14\n",
        "    enc_bottleneck = base_model.get_layer('relu').output                 # 7x7\n",
        "\n",
        "    # --- DECODER ---\n",
        "    # Level 4\n",
        "    x = layers.Conv2D(256, 3, padding='same', activation='relu')(enc_bottleneck)\n",
        "    x = layers.UpSampling2D()(x)\n",
        "    enc4_lat = layers.Conv2D(256, 1, padding='same')(enc_block4)\n",
        "    nuc_m4 = layers.Add()([x, enc4_lat])\n",
        "    con_m4 = layers.Add()([x, enc4_lat])\n",
        "    nuc_d4, con_d4 = IAM_Module(nuc_m4, con_m4, 256, name=\"IAM_4\")\n",
        "\n",
        "    # Level 3\n",
        "    nuc_up3 = layers.Conv2D(128, 1, padding='same')(layers.UpSampling2D()(nuc_d4))\n",
        "    con_up3 = layers.Conv2D(128, 1, padding='same')(layers.UpSampling2D()(con_d4))\n",
        "    enc3_lat = layers.Conv2D(128, 1, padding='same')(enc_block3)\n",
        "    nuc_m3 = layers.Add()([nuc_up3, enc3_lat])\n",
        "    con_m3 = layers.Add()([con_up3, enc3_lat])\n",
        "    nuc_d3, con_d3 = IAM_Module(nuc_m3, con_m3, 128, name=\"IAM_3\")\n",
        "\n",
        "    # Level 2\n",
        "    nuc_up2 = layers.Conv2D(64, 1, padding='same')(layers.UpSampling2D()(nuc_d3))\n",
        "    con_up2 = layers.Conv2D(64, 1, padding='same')(layers.UpSampling2D()(con_d3))\n",
        "    enc2_lat = layers.Conv2D(64, 1, padding='same')(enc_block2)\n",
        "    nuc_m2 = layers.Add()([nuc_up2, enc2_lat])\n",
        "    con_m2 = layers.Add()([con_up2, enc2_lat])\n",
        "    nuc_d2, con_d2 = IAM_Module(nuc_m2, con_m2, 64, name=\"IAM_2\")\n",
        "\n",
        "    # Level 1\n",
        "    nuc_up1 = layers.Conv2D(32, 1, padding='same')(layers.UpSampling2D()(nuc_d2))\n",
        "    con_up1 = layers.Conv2D(32, 1, padding='same')(layers.UpSampling2D()(con_d2))\n",
        "    enc1_lat = layers.Conv2D(32, 1, padding='same')(enc_block1)\n",
        "    nuc_m1 = layers.Add()([nuc_up1, enc1_lat])\n",
        "    con_m1 = layers.Add()([con_up1, enc1_lat])\n",
        "    nuc_d1, con_d1 = IAM_Module(nuc_m1, con_m1, 32, name=\"IAM_1\")\n",
        "\n",
        "    # Output\n",
        "    nuc_final = layers.UpSampling2D()(nuc_d1)\n",
        "    con_final = layers.UpSampling2D()(con_d1)\n",
        "\n",
        "    nuc_out = layers.Conv2D(1, 1, activation='sigmoid', name='nuclei_output', dtype='float32')(nuc_final)\n",
        "    con_out = layers.Conv2D(1, 1, activation='sigmoid', name='contour_output', dtype='float32')(con_final)\n",
        "\n",
        "    return models.Model(inputs=inputs, outputs=[nuc_out, con_out], name=\"CIA-Net\")\n",
        "\n",
        "model = build_cia_net((224, 224, 3))\n",
        "print(f\"{Colors.SUCCESS}[OK] CIA-Net Model Built.{Colors.ENDC}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzWk81NPDgKu"
      },
      "source": [
        "## 5. Training Components\n",
        "Definitions for custom Loss Functions, Metrics, and the specific AJI Monitor Callback used for model checkpointing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRFTHBUPDgKu"
      },
      "outputs": [],
      "source": [
        "# --- Loss Functions ---\n",
        "class SmoothTruncatedLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, gamma=0.2, name=\"smooth_truncated_loss\"):\n",
        "        super().__init__(name=name)\n",
        "        self.gamma = gamma\n",
        "    def call(self, y_true, y_pred):\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        y_pred = tf.cast(y_pred, tf.float32)\n",
        "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0 - 1e-7)\n",
        "        pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
        "        loss_outlier = -tf.math.log(self.gamma) + 0.5 * (1 - (pt**2)/(self.gamma**2))\n",
        "        loss_inlier = -tf.math.log(pt)\n",
        "        return tf.reduce_mean(tf.where(pt < self.gamma, loss_outlier, loss_inlier))\n",
        "\n",
        "def soft_dice_loss(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32); y_pred = tf.cast(y_pred, tf.float32)\n",
        "    numerator = 2 * tf.reduce_sum(y_true * y_pred) + 1e-5\n",
        "    denominator = tf.reduce_sum(y_true**2) + tf.reduce_sum(y_pred**2) + 1e-5\n",
        "    return 1 - (numerator / denominator)\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
        "    smooth = 1e-5\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n",
        "    dice_loss = 1 - ((2. * intersection + smooth) / (union + smooth))\n",
        "    return bce + dice_loss\n",
        "\n",
        "# --- Metrics ---\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32); y_pred = tf.cast(y_pred, tf.float32)\n",
        "    y_pred_thresh = tf.cast(y_pred > 0.5, tf.float32)\n",
        "    intersection = K.sum(y_true * y_pred_thresh)\n",
        "    return (2. * intersection + 1e-5) / (K.sum(y_true) + K.sum(y_pred_thresh) + 1e-5)\n",
        "\n",
        "# --- Callbacks ---\n",
        "class AJIMonitor(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, val_dataset, freq=2):\n",
        "        super().__init__()\n",
        "        self.val_dataset = val_dataset\n",
        "        self.freq = freq\n",
        "        self.best_aji = 0.0\n",
        "\n",
        "    def calculate_aji_vectorized(self, gt_mask, pred_mask):\n",
        "        # Fast approximation: IoU over global batch\n",
        "        intersection = np.logical_and(gt_mask, pred_mask).sum()\n",
        "        union = np.logical_or(gt_mask, pred_mask).sum()\n",
        "        return intersection / (union + 1e-7)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % self.freq != 0: return\n",
        "\n",
        "        aji_scores = []\n",
        "        # Sample limited batch for speed (20 batches)\n",
        "        for images, targets in self.val_dataset.take(20):\n",
        "            preds = self.model.predict(images, verbose=0)\n",
        "            nucs = preds[0]\n",
        "\n",
        "            for i in range(images.shape[0]):\n",
        "                pred_mask = (nucs[i,:,:,0] > 0.5).astype(np.uint8)\n",
        "                gt_mask = targets['nuclei_output'][i,:,:,0].numpy().astype(np.uint8)\n",
        "                score = self.calculate_aji_vectorized(gt_mask, pred_mask)\n",
        "                aji_scores.append(score)\n",
        "\n",
        "        mean_aji = np.mean(aji_scores)\n",
        "        print(f\"\\n{Colors.INFO}[AJI Monitor] Val AJI (Approx): {mean_aji:.4f} (Best: {self.best_aji:.4f}){Colors.ENDC}\")\n",
        "        logs['val_aji'] = mean_aji\n",
        "\n",
        "        if mean_aji > self.best_aji:\n",
        "            self.best_aji = mean_aji\n",
        "            self.model.save_weights(os.path.join(DRIVE_DATA_PATH, 'cia_net_best_aji.weights.h5'))\n",
        "\n",
        "print(f\"{Colors.SUCCESS}[OK] Loss Functions & Monitors Ready.{Colors.ENDC}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9HzOJAVDgKv"
      },
      "source": [
        "## 6. Execution: 3-Stage Training Strategy\n",
        "Implements a production-grade automated training loop:\n",
        "1.  **Warm-up:** Frozen encoder, high LR.\n",
        "2.  **Stabilization:** Full network, moderate LR, standard loss.\n",
        "3.  **SOTA Fine-tuning:** Advanced Optimizer (AdamW + Cosine Decay) & Robust Loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvnG1igiDgKv"
      },
      "outputs": [],
      "source": [
        "# --- 0. SAFETY CHECKS ---\n",
        "print(f\"{Colors.INFO}Config: Warmup={WARMUP_EPOCHS}, Rescue={RESCUE_EPOCHS}, SOTA={SOTA_EPOCHS}{Colors.ENDC}\")\n",
        "\n",
        "if 'model' in globals() and 'history_3' in globals():\n",
        "    print(f\"{Colors.SUCCESS}Training appears complete. Saving backup weights.{Colors.ENDC}\")\n",
        "    model.save_weights(os.path.join(DRIVE_DATA_PATH, 'cia_net_final_sota.weights.h5'))\n",
        "else:\n",
        "    K.clear_session()\n",
        "    try:\n",
        "        model = build_cia_net((IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "    except NameError:\n",
        "        raise RuntimeError(\"Build function not found. Run previous cells.\")\n",
        "\n",
        "    print(f\"{Colors.HEADER}Starting Fresh Model Training...{Colors.ENDC}\")\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # PHASE 1: WARM-UP (Frozen Encoder)\n",
        "    # ---------------------------------------------------------\n",
        "    print(f\"\\n{Colors.INFO}>>> PHASE 1: WARM-UP (Frozen Encoder)...{Colors.ENDC}\")\n",
        "    for layer in model.layers:\n",
        "        if 'densenet121' in layer.name or 'input' in layer.name:\n",
        "            layer.trainable = False\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "        loss={'nuclei_output': bce_dice_loss, 'contour_output': bce_dice_loss},\n",
        "        loss_weights={'nuclei_output': 1.0, 'contour_output': 0.5},\n",
        "        metrics={'nuclei_output': ['accuracy', dice_coef], 'contour_output': [dice_coef]}\n",
        "    )\n",
        "\n",
        "    history_1 = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=test_ds,\n",
        "        epochs=WARMUP_EPOCHS,\n",
        "        callbacks=[tf.keras.callbacks.CSVLogger(os.path.join(DRIVE_DATA_PATH, 'log_phase1.csv'))]\n",
        "    )\n",
        "    model.save_weights(os.path.join(DRIVE_DATA_PATH, 'weights_phase1.weights.h5'))\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # PHASE 2: STABILIZATION (Full Network)\n",
        "    # ---------------------------------------------------------\n",
        "    print(f\"\\n{Colors.INFO}>>> PHASE 2: STABILIZATION (Full Network)...{Colors.ENDC}\")\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = True\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "        loss={'nuclei_output': bce_dice_loss, 'contour_output': bce_dice_loss},\n",
        "        loss_weights={'nuclei_output': 1.0, 'contour_output': 1.0},\n",
        "        metrics={'nuclei_output': ['accuracy', dice_coef], 'contour_output': [dice_coef]}\n",
        "    )\n",
        "\n",
        "    history_2 = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=test_ds,\n",
        "        epochs=RESCUE_EPOCHS,\n",
        "        callbacks=[\n",
        "            tf.keras.callbacks.ModelCheckpoint(\n",
        "                os.path.join(DRIVE_DATA_PATH, 'weights_phase2_best.keras'),\n",
        "                save_best_only=True, monitor='val_nuclei_output_dice_coef', mode='max'\n",
        "            ),\n",
        "            tf.keras.callbacks.CSVLogger(os.path.join(DRIVE_DATA_PATH, 'log_phase2.csv'))\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # PHASE 3: SOTA FINE-TUNING (Advanced)\n",
        "    # ---------------------------------------------------------\n",
        "    print(f\"\\n{Colors.INFO}>>> PHASE 3: SOTA FINE-TUNING...{Colors.ENDC}\")\n",
        "    try:\n",
        "        model.load_weights(os.path.join(DRIVE_DATA_PATH, 'weights_phase2_best.keras'))\n",
        "        print(f\"{Colors.SUCCESS}Loaded Best Phase 2 Weights.{Colors.ENDC}\")\n",
        "    except:\n",
        "        print(f\"{Colors.WARNING}Warning: Phase 2 weights not found, continuing...{Colors.ENDC}\")\n",
        "\n",
        "    steps_per_epoch = len(X_train_raw) * 10 // BATCH_SIZE\n",
        "    lr_schedule = tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
        "        initial_learning_rate=1e-4, first_decay_steps=20 * steps_per_epoch,\n",
        "        t_mul=2.0, m_mul=0.9, alpha=1e-6\n",
        "    )\n",
        "    optimizer = tf.keras.optimizers.AdamW(\n",
        "        learning_rate=lr_schedule, weight_decay=1e-4, global_clipnorm=1.0\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss={'nuclei_output': SmoothTruncatedLoss(gamma=GAMMA_STL), 'contour_output': soft_dice_loss},\n",
        "        loss_weights={'nuclei_output': 1.0, 'contour_output': LAMBDA_CONTOUR},\n",
        "        metrics={\n",
        "            'nuclei_output': [\n",
        "                'accuracy', dice_coef,\n",
        "                tf.keras.metrics.Precision(name='precision'),\n",
        "                tf.keras.metrics.Recall(name='recall')\n",
        "            ],\n",
        "            'contour_output': [dice_coef]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    history_3 = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=test_ds,\n",
        "        epochs=SOTA_EPOCHS,\n",
        "        callbacks=[\n",
        "            tf.keras.callbacks.ModelCheckpoint(\n",
        "                os.path.join(DRIVE_DATA_PATH, 'cia_net_final_sota.keras'),\n",
        "                save_best_only=True, monitor='val_nuclei_output_dice_coef', mode='max', verbose=1\n",
        "            ),\n",
        "            tf.keras.callbacks.EarlyStopping(\n",
        "                monitor='val_nuclei_output_dice_coef', patience=25, mode='max', restore_best_weights=True\n",
        "            ),\n",
        "            tf.keras.callbacks.CSVLogger(os.path.join(DRIVE_DATA_PATH, 'log_phase3.csv')),\n",
        "            AJIMonitor(test_ds, freq=5)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print(f\"{Colors.SUCCESS}All Training Phases Completed Successfully!{Colors.ENDC}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kd3P2ExDgKy"
      },
      "source": [
        "## 7. Inference & Explainability (XAI)\n",
        "Performs advanced post-processing (Watershed) and generates an XAI visualization panel showing Uncertainty, Error Maps, and Instance Segmentation results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KF2pmppDgKy"
      },
      "outputs": [],
      "source": [
        "from skimage.segmentation import watershed\n",
        "from skimage.feature import peak_local_max\n",
        "\n",
        "# --- Post-Processing Logic ---\n",
        "def sophisticated_post_processing(pred_nuc, pred_con):\n",
        "    nuc_mask = (pred_nuc > 0.5).astype(np.uint8)\n",
        "    con_mask = (pred_con > 0.3).astype(np.uint8)\n",
        "\n",
        "    markers_raw = np.clip(nuc_mask - con_mask, 0, 1)\n",
        "    kernel = np.ones((3,3), np.uint8)\n",
        "    markers_clean = cv2.morphologyEx(markers_raw, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "\n",
        "    distance = ndi.distance_transform_edt(markers_clean)\n",
        "    coords = peak_local_max(distance, footprint=np.ones((3, 3)), labels=markers_clean)\n",
        "    mask = np.zeros(distance.shape, dtype=bool)\n",
        "    mask[tuple(coords.T)] = True\n",
        "    markers, _ = ndi.label(mask)\n",
        "\n",
        "    final_labels = watershed(-distance, markers, mask=nuc_mask)\n",
        "    return (final_labels > 0).astype(float)\n",
        "\n",
        "def paper_post_processing(pred_nuc, pred_con):\n",
        "    diff = pred_nuc - pred_con\n",
        "    binary = (diff > 0.3).astype(np.uint8)\n",
        "    cleaned = cv2.morphologyEx(binary, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
        "    return cleaned.astype(float)\n",
        "\n",
        "def compute_entropy(probs):\n",
        "    probs = np.clip(probs, 1e-7, 1 - 1e-7)\n",
        "    entropy = - (probs * np.log(probs) + (1 - probs) * np.log(1 - probs))\n",
        "    return entropy\n",
        "\n",
        "# --- Visualization Engine ---\n",
        "def visualize_xai_quality(model, dataset, num_samples=3):\n",
        "    images, targets = next(iter(dataset.take(1)))\n",
        "    imgs = images[:num_samples]\n",
        "    gt_nuc = targets['nuclei_output'][:num_samples]\n",
        "\n",
        "    print(f\"{Colors.INFO}Generating Predictions...{Colors.ENDC}\")\n",
        "    preds = model.predict(imgs, verbose=0)\n",
        "    pred_nuc = preds[0]\n",
        "    pred_con = preds[1]\n",
        "\n",
        "    plt.figure(figsize=(24, 6 * num_samples))\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        final_mask = sophisticated_post_processing(pred_nuc[i,:,:,0], pred_con[i,:,:,0])\n",
        "        paper_mask = paper_post_processing(pred_nuc[i,:,:,0], pred_con[i,:,:,0])\n",
        "        entropy = compute_entropy(pred_nuc[i,:,:,0])\n",
        "\n",
        "        gt_mask = gt_nuc[i,:,:,0].numpy()\n",
        "        error_map = np.zeros((224, 224, 3))\n",
        "        error_map[(gt_mask == 1) & (final_mask == 1)] = [1, 1, 0] # Yellow: TP\n",
        "        error_map[(gt_mask == 1) & (final_mask == 0)] = [1, 0, 0] # Red: FN\n",
        "        error_map[(gt_mask == 0) & (final_mask == 1)] = [0, 0, 1] # Blue: FP\n",
        "\n",
        "        titles = [\"Original\", \"Nuclei Prob\", \"Contour Prob\", \"Uncertainty\", \"Paper Method\", \"SOTA Watershed\", \"Error Map (Y:TP)\"]\n",
        "        contents = [imgs[i], pred_nuc[i,:,:,0], pred_con[i,:,:,0], entropy, paper_mask, final_mask, error_map]\n",
        "        cmaps = [None, 'jet', 'magma', 'inferno', 'gray', 'gray', None]\n",
        "\n",
        "        for j, (title, content, cmap) in enumerate(zip(titles, contents, cmaps)):\n",
        "            plt.subplot(num_samples, 7, i*7 + j + 1)\n",
        "            plt.imshow(content, cmap=cmap)\n",
        "            plt.title(title, fontsize=10)\n",
        "            plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    save_path = os.path.join(DRIVE_DATA_PATH, 'advanced_xai_analysis_sota.png')\n",
        "    plt.savefig(save_path, dpi=300)\n",
        "    print(f\"{Colors.SUCCESS}Visualization Saved: {save_path}{Colors.ENDC}\")\n",
        "    plt.show()\n",
        "\n",
        "visualize_xai_quality(model, test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBkmTdlDDgKz"
      },
      "source": [
        "## 8. Quantitative Analysis (Training History)\n",
        "Consolidates logs from all 3 training phases into a single, comprehensive visualization of performance convergence and stability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOT909-lDgKz"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "def plot_robust_training_history():\n",
        "    log_files = [\n",
        "        ('log_phase1.csv', 'Phase 1: Warm-up (Encoder Frozen)'),\n",
        "        ('log_phase2.csv', 'Phase 2: Rescue/Stabilization (Full Net)'),\n",
        "        ('log_phase3.csv', 'Phase 3: SOTA Fine-tuning (AdamW + Cosine)')\n",
        "    ]\n",
        "\n",
        "    dfs = []\n",
        "    cumulative_epoch = 0\n",
        "    phase_markers = []\n",
        "\n",
        "    print(f\"{Colors.INFO}Analyzing Training Logs...{Colors.ENDC}\")\n",
        "\n",
        "    for filename, label in log_files:\n",
        "        path = os.path.join(DRIVE_DATA_PATH, filename)\n",
        "        if os.path.exists(path):\n",
        "            try:\n",
        "                df = pd.read_csv(path)\n",
        "                if len(df) > 0:\n",
        "                    df['epoch'] = df['epoch'] + cumulative_epoch\n",
        "                    dfs.append(df)\n",
        "                    cumulative_epoch += len(df)\n",
        "                    phase_markers.append((cumulative_epoch, label))\n",
        "                    print(f\"{filename} loaded ({len(df)} epochs)\")\n",
        "            except Exception as e:\n",
        "                print(f\"{filename} error: {e}\")\n",
        "        else:\n",
        "            print(f\"{filename} not found.\")\n",
        "\n",
        "    if not dfs:\n",
        "        print(f\"{Colors.ERROR}No logs found.{Colors.ENDC}\")\n",
        "        return\n",
        "\n",
        "    full_df = pd.concat(dfs, ignore_index=True)\n",
        "    sns.set_theme(style=\"whitegrid\")\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(24, 8))\n",
        "\n",
        "    color_train = '#2ecc71'\n",
        "    color_val_nuc = '#3498db'\n",
        "    color_val_con = '#e67e22'\n",
        "\n",
        "    # --- Dice Score ---\n",
        "    ax1 = axes[0]\n",
        "    sns.lineplot(data=full_df, x='epoch', y='nuclei_output_dice_coef', ax=ax1, label='Train Nuclei Dice', color=color_train, linewidth=2, alpha=0.7)\n",
        "    sns.lineplot(data=full_df, x='epoch', y='val_nuclei_output_dice_coef', ax=ax1, label='Val Nuclei Dice', color=color_val_nuc, linewidth=3)\n",
        "\n",
        "    if 'val_contour_output_dice_coef' in full_df.columns:\n",
        "        sns.lineplot(data=full_df, x='epoch', y='val_contour_output_dice_coef', ax=ax1, label='Val Contour Dice', color=color_val_con, linestyle='--', linewidth=2)\n",
        "\n",
        "    best_idx = full_df['val_nuclei_output_dice_coef'].idxmax()\n",
        "    best_epoch = full_df.loc[best_idx, 'epoch']\n",
        "    best_score = full_df.loc[best_idx, 'val_nuclei_output_dice_coef']\n",
        "\n",
        "    ax1.scatter(best_epoch, best_score, color='red', s=100, zorder=5, label=f'Best: {best_score:.4f}')\n",
        "    ax1.set_title('Segmentation Performance (Dice Score)', fontsize=16, fontweight='bold')\n",
        "    ax1.set_xlabel('Epochs', fontsize=14)\n",
        "    ax1.set_ylabel('Dice Coefficient', fontsize=14)\n",
        "    ax1.set_ylim(0, 1.0)\n",
        "    ax1.legend(loc='lower right', fontsize=12, frameon=True)\n",
        "\n",
        "    for epoch, label in phase_markers[:-1]:\n",
        "        ax1.axvline(x=epoch, color='gray', linestyle=':', linewidth=2)\n",
        "        ax1.text(epoch + 1, 0.05, label.split(':')[0], rotation=90, color='gray', fontweight='bold')\n",
        "\n",
        "    # --- Loss ---\n",
        "    ax2 = axes[1]\n",
        "    sns.lineplot(data=full_df, x='epoch', y='loss', ax=ax2, label='Total Train Loss', color=color_train, linewidth=2, alpha=0.7)\n",
        "    sns.lineplot(data=full_df, x='epoch', y='val_loss', ax=ax2, label='Total Val Loss', color='green', linewidth=3)\n",
        "\n",
        "    ax2.set_title('Loss Convergence', fontsize=16, fontweight='bold')\n",
        "    ax2.set_xlabel('Epochs', fontsize=14)\n",
        "    ax2.set_ylabel('Loss Value', fontsize=14)\n",
        "    ax2.legend(loc='upper right', fontsize=12, frameon=True)\n",
        "\n",
        "    for epoch, label in phase_markers[:-1]:\n",
        "        ax2.axvline(x=epoch, color='red', linestyle='--', linewidth=1.5)\n",
        "        ax2.text(epoch + 1, full_df['loss'].max()*0.8, label.split(':')[0], rotation=90, color='red', fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    save_path = os.path.join(DRIVE_DATA_PATH, 'robust_training_history.png')\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"{Colors.SUCCESS}History Plot Saved: {save_path}{Colors.ENDC}\")\n",
        "    plt.show()\n",
        "\n",
        "plot_robust_training_history()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}